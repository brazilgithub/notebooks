{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ENTAR Eng",
      "provenance": [],
      "collapsed_sections": [
        "c7VjlYb2H9Ph",
        "ECm1EEXpPaTZ",
        "ZjPqTBNoohK9",
        "4AVBicY8T8XY",
        "148dzAWOTw29",
        "a165mYFXow8I",
        "lEhNSwi50Wa5",
        "hCmtWECtAE8X",
        "m0S8PshiV_aq",
        "Uu22Uwc3V_aw",
        "rDF6s4jYYF7I"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_-MnB32R4kZ"
      },
      "source": [
        "#@title ##**Install all the necessary libraries** { display-mode: \"form\" }\n",
        "!pip install youtube_dl\n",
        "!pip install ffmpeg\n",
        "!pip install ffmpeg-python\n",
        "!pip install torchvision==0.5\n",
        "!pip install torch==1.4\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from google.colab import files\n",
        "import imageio\n",
        "import youtube_dl\n",
        "import cv2\n",
        "import os\n",
        "import torch\n",
        "import fastai\n",
        "import ffmpeg\n",
        "import os.path as osp\n",
        "import logging\n",
        "import shutil\n",
        "import re\n",
        "import gc\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from os import path\n",
        "import numpy as np\n",
        "import moviepy.editor as mpy\n",
        "from moviepy.video.io.ffmpeg_writer import FFMPEG_VideoWriter\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import glob\n",
        "from IPython import display as ipythondisplay\n",
        "from IPython.display import Image as ipythonimage\n",
        "torch.backends.cudnn.benchmark=True\n",
        "%matplotlib inline\n",
        "\n",
        "!rm -rf sample_data\n",
        "clear_output()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bhwpq1R38FPw"
      },
      "source": [
        "#@title ##**Upload video** { display-mode: \"form\" }\n",
        "#@markdown *Enter a link to the video below (for example, YouTube or Twitter), or leave the **source_url** field blank (in this case, you will be asked to upload the video from your computer).*\n",
        "source_url = '' #@param {type:\"string\"}\n",
        "\n",
        "if source_url == '':\n",
        "  uploaded = files.upload()\n",
        "  for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "        name=fn, length=len(uploaded[fn])))\n",
        "  os.rename(fn, fn.replace(\" \", \"\"))\n",
        "  fn = fn.replace(\" \", \"\")\n",
        "  file_name = \"downloaded_video.\" + fn.split(\".\")[-1]\n",
        "  !mv -f $fn $file_name\n",
        "\n",
        "else:\n",
        "  try:\n",
        "    ydl_opts = {\n",
        "        'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4',\n",
        "        'outtmpl': 'downloaded_video.mp4',\n",
        "        }\n",
        "    with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "      ydl.download([source_url])\n",
        "    file_name = 'downloaded_video.mp4'\n",
        "  \n",
        "  except BaseException:\n",
        "    !wget $source_url\n",
        "    fn = source_url.split('/')[-1]\n",
        "    os.rename(fn, fn.replace(\" \", \"\"))\n",
        "    fn = fn.replace(\" \", \"\")\n",
        "    file_name = \"downloaded_video.\" + fn.split(\".\")[-1]\n",
        "    !mv -f $fn $file_name\n",
        "\n",
        "!cp -r downloaded_video.mp4 video.mp4\n",
        "clear_output()\n",
        "fps_of_video = int(cv2.VideoCapture(file_name).get(cv2.CAP_PROP_FPS))\n",
        "frames_of_video = int(cv2.VideoCapture(file_name).get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "#@markdown *Downloading videos lasting longer than one minute is not recommended. In addition, don't upload video that have a \"space\" or a \"dot\" in the title.*\n",
        "\n",
        "#@markdown *If there is an error during execution, then run this block again*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AVBicY8T8XY"
      },
      "source": [
        "---\n",
        "# <b><font color=\"gree\" size=\"+3\">2. Enhancing video ([EDVR](https://github.com/xinntao/EDVR))\n",
        "*↓ Click to open section ↓*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8udPfjMUJHZ"
      },
      "source": [
        "#@title ##**Clone the repository and upload the pre-trained model** { display-mode: \"form\" }\n",
        "%cd /content\n",
        "!pip install numpy opencv-python lmdb pyyaml\n",
        "!pip install tb-nightly future\n",
        "!git clone https://github.com/brazilgithub/EDVR\n",
        "%cd /content/EDVR/codes/models/archs/dcn\n",
        "!python setup.py develop\n",
        "%cd /content/EDVR/codes\n",
        "!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1zEV4w2rDEtAIWgJCe0Zki7lssCEaQfiU' -O /content/EDVR/experiments/pretrained_models/EDVR_REDS_deblurcomp_L.pth\n",
        "clear_output()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPdZEJiFVoPf"
      },
      "source": [
        "#@title ##**Initialize the necessary functions** { display-mode: \"form\" }\n",
        "import utils.util as util\n",
        "import data.util as data_util\n",
        "import models.archs.EDVR_arch as EDVR_arch\n",
        "\n",
        "workfolder = Path('./video')\n",
        "source_folder = workfolder / \"source\"\n",
        "inframes_root = workfolder / \"inframes\"\n",
        "audio_root = workfolder / \"audio\"\n",
        "outframes_root = workfolder / \"outframes\"\n",
        "result_folder = workfolder / \"result\"\n",
        "pretrained_models = Path('../experiments/pretrained_models')\n",
        "\n",
        "def clean_mem():\n",
        "    # torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "def get_fps(source_path: Path) -> str:\n",
        "    print(source_path)\n",
        "    probe = ffmpeg.probe(str(source_path))\n",
        "    stream_data = next(\n",
        "        (stream for stream in probe['streams'] if stream['codec_type'] == 'video'),\n",
        "        None,\n",
        "    )\n",
        "    return stream_data['avg_frame_rate']\n",
        "\n",
        "def preProcess(imag_path_l, multiple):\n",
        "  '''Need to resize images for blurred model (needs to be multiples of 16)'''\n",
        "  for img_path in imag_path_l:\n",
        "    im = Image.open(img_path)\n",
        "    h, w = im.size\n",
        "    # resize so they are multiples of 4 or 16 (for blurred)\n",
        "    h = h - h % multiple\n",
        "    w = w - w % multiple\n",
        "    im = im.resize((h,w))\n",
        "    im.save(img_path)\n",
        "\n",
        "def purge_images(dir):\n",
        "  for f in os.listdir(dir):\n",
        "    if re.search('.*?\\.jpg', f):\n",
        "      os.remove(os.path.join(dir, f))\n",
        "\n",
        "def extract_raw_frames(source_path: Path):\n",
        "    inframes_folder = inframes_root / (source_path.stem)\n",
        "    inframe_path_template = str(inframes_folder / '%5d.jpg')\n",
        "    inframes_folder.mkdir(parents=True, exist_ok=True)\n",
        "    purge_images(inframes_folder)\n",
        "    ffmpeg.input(str(source_path)).output(\n",
        "        str(inframe_path_template), format='image2', vcodec='mjpeg', qscale=0\n",
        "    ).run(capture_stdout=True)\n",
        "\n",
        "def make_subfolders(img_path_l, chunk_size):\n",
        "  i = 0\n",
        "  subFolderList = []\n",
        "  source_img_path = Path('/content/EDVR/codes/video/inframes/video_subfolders')\n",
        "  source_img_path.mkdir(parents=True, exist_ok=True)\n",
        "  for img in img_path_l:\n",
        "    if i % chunk_size == 0:\n",
        "      img_path = source_img_path / str(i)\n",
        "      img_path.mkdir(parents=True, exist_ok=True)\n",
        "      subFolderList.append(str(img_path))\n",
        "    i+=1\n",
        "    img_name = osp.basename(img)\n",
        "    img_path_name = img_path / img_name\n",
        "    shutil.copyfile(img, img_path_name)\n",
        "\n",
        "  return subFolderList\n",
        "\n",
        "def remove_subfolders():\n",
        "  shutil.rmtree('/content/EDVR/codes/video/inframes/video_subfolders', ignore_errors=True, onerror=None)\n",
        "\n",
        "def edvrPredict(data_mode, chunk_size, stage):\n",
        "  device = torch.device('cuda')\n",
        "  os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "  data_mode = \"blur_comp\"\n",
        "  stage = stage  # 1 or 2, use two stage strategy for REDS dataset.\n",
        "  flip_test = False\n",
        "  model_path = pretrained_models / 'EDVR_REDS_deblurcomp_L.pth'   \n",
        "\n",
        "  print('Model Used: ', model_path)\n",
        "  \n",
        "  if data_mode == 'Vid4':\n",
        "      N_in = 7  # use N_in images to restore one HR image\n",
        "  else:\n",
        "      N_in = 5\n",
        "\n",
        "  predeblur, HR_in = False, False\n",
        "  back_RBs = 40\n",
        "  if data_mode == 'blur' or data_mode == 'blur_comp':\n",
        "      predeblur, HR_in = True, True\n",
        "  if stage == 2:\n",
        "      HR_in = True\n",
        "      back_RBs = 20\n",
        "  if data_mode == 'TOF':\n",
        "    model = TOF_arch.TOFlow(adapt_official=True)\n",
        "  else:\n",
        "    model = EDVR_arch.EDVR(128, N_in, 8, 5, back_RBs, predeblur=predeblur, HR_in=HR_in)\n",
        "\n",
        "  #### dataset\n",
        "  test_dataset_folder = '/content/EDVR/codes/video/inframes'\n",
        "\n",
        "  #### evaluation\n",
        "  crop_border = 0\n",
        "  border_frame = N_in // 2  # border frames when evaluate\n",
        "  # temporal padding mode\n",
        "  if data_mode in ('Vid4','sharp_bicubic'):\n",
        "      padding = 'new_info'\n",
        "  else:\n",
        "      padding = 'replicate'\n",
        "  save_imgs = True\n",
        "\n",
        "  save_folder = '/content/EDVR/codes/video/outframes'\n",
        "  util.mkdirs(save_folder)\n",
        "\n",
        "  #### set up the models\n",
        "  model.load_state_dict(torch.load(model_path), strict=True)\n",
        "  model.eval()\n",
        "  model = model.to(device)\n",
        "\n",
        "  avg_psnr_l, avg_psnr_center_l, avg_psnr_border_l = [], [], []\n",
        "  subfolder_name_l = []\n",
        "  # remove old video_subfolder if exists\n",
        "  remove_subfolders()\n",
        "  subfolder_l = sorted(glob.glob(osp.join(test_dataset_folder, '*')))\n",
        "\n",
        "  # for each subfolder\n",
        "  for subfolder in subfolder_l:\n",
        "      subfolder_name = osp.basename(subfolder)\n",
        "      subfolder_name_l.append(subfolder_name)\n",
        "      save_subfolder = osp.join(save_folder, subfolder_name)\n",
        "\n",
        "      img_path_l = sorted(glob.glob(osp.join(subfolder, '*')))\n",
        "      if save_imgs:\n",
        "          util.mkdirs(save_subfolder)\n",
        "          purge_images(save_subfolder)\n",
        "\n",
        "      # preprocess images (needed for blurred models)\n",
        "      if predeblur:\n",
        "        preProcess(img_path_l, 16)\n",
        "      else:\n",
        "        preProcess(img_path_l, 4)\n",
        "      # make even more subfolders\n",
        "      subFolderList = make_subfolders(img_path_l, chunk_size)\n",
        "\n",
        "      #### read LQ and GT images in chunks of 1000\n",
        "      for subSubFolder in subFolderList:\n",
        "        clean_mem()\n",
        "        imgs_LQ = data_util.read_img_seq(subSubFolder)\n",
        "        subSubFolder_l = sorted(glob.glob(osp.join(subSubFolder, '*')))\n",
        "        max_idx = len(subSubFolder_l)\n",
        "        avg_psnr, avg_psnr_border, avg_psnr_center, N_border, N_center = 0, 0, 0, 0, 0\n",
        "\n",
        "        # process each image\n",
        "        for img_idx, img_path in tqdm(enumerate(subSubFolder_l)):\n",
        "            img_name = osp.splitext(osp.basename(img_path))[0]\n",
        "            select_idx = data_util.index_generation(img_idx, max_idx, N_in, padding=padding)\n",
        "            imgs_in = imgs_LQ.index_select(0, torch.LongTensor(select_idx)).unsqueeze(0).to(device)\n",
        "\n",
        "            if flip_test:\n",
        "                output = util.flipx4_forward(model, imgs_in)\n",
        "            else:\n",
        "                output = util.single_forward(model, imgs_in)\n",
        "            output = util.tensor2img(output.squeeze(0))\n",
        "\n",
        "            if save_imgs:\n",
        "                cv2.imwrite(osp.join(save_subfolder, '{}.jpg'.format(img_name)), output)\n",
        "                # print('Saved Image:', str(osp.join(save_subfolder, '{}.jpg'.format(img_name))))\n",
        "\n",
        "def moveProcessedFrames():\n",
        "  shutil.rmtree('/content/EDVR/codes/video/inframes')\n",
        "  os.rename('/content/EDVR/codes/video/outframes', '/content/EDVR/codes/video/inframes')\n",
        "\n",
        "def build_video(source_path: Path) -> Path:\n",
        "        out_path = result_folder / (\n",
        "            source_path.name.replace('.mp4', '_no_audio.mp4')\n",
        "        )\n",
        "        outframes_folder = outframes_root / (source_path.stem)\n",
        "        outframes_path_template = str(outframes_folder / '%5d.jpg')\n",
        "        out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        if out_path.exists():\n",
        "            out_path.unlink()\n",
        "        fps = get_fps(source_path)\n",
        "        print('Original FPS is: ', fps)\n",
        "\n",
        "        ffmpeg.input(\n",
        "            str(outframes_path_template),\n",
        "            format='image2',\n",
        "            vcodec='mjpeg',\n",
        "            framerate=fps,\n",
        "        ).output(str(out_path), crf=17, vcodec='libx264').run(capture_stdout=True)\n",
        "\n",
        "        result_path = result_folder / source_path.name\n",
        "        if result_path.exists():\n",
        "            result_path.unlink()\n",
        "        # making copy of non-audio version in case adding back audio doesn't apply or fails.\n",
        "        shutil.copyfile(str(out_path), str(result_path))\n",
        "\n",
        "        # adding back sound here\n",
        "        audio_file = Path(str(source_path).replace('.mp4', '.aac'))\n",
        "        if audio_file.exists():\n",
        "            audio_file.unlink()\n",
        "\n",
        "        os.system(\n",
        "            'ffmpeg -y -i \"'\n",
        "            + str(source_path)\n",
        "            + '\" -vn -acodec copy \"'\n",
        "            + str(audio_file)\n",
        "            + '\"'\n",
        "        )\n",
        "\n",
        "        if audio_file.exists:\n",
        "            os.system(\n",
        "                'ffmpeg -y -i \"'\n",
        "                + str(out_path)\n",
        "                + '\" -i \"'\n",
        "                + str(audio_file)\n",
        "                + '\" -shortest -c:v copy -c:a aac -b:a 256k \"'\n",
        "                + str(result_path)\n",
        "                + '\"'\n",
        "            )\n",
        "        print('Video created here: ' + str(result_path))\n",
        "        return result_path\n",
        "\n",
        "def edvr_video(source_path: Path, chunk_size: int):\n",
        "    # extract frames\n",
        "    extract_raw_frames(source_path)\n",
        "\n",
        "    # process frames\n",
        "    edvrPredict(\"blur_comp\", chunk_size, 1)\n",
        "\n",
        "    # build back video\n",
        "    build_video(source_path)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGEngN6UXAcZ"
      },
      "source": [
        "#@title ##**Enhancing the quality of frames** { display-mode: \"form\" }\n",
        "%%time\n",
        "edvr_video(Path('/content/video.mp4'), 100)\n",
        "clear_output()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwwhj7Rf4v0k",
        "outputId": "98f258d6-06c5-4214-cf1a-4c699871abdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "#@title ##**Get result** { display-mode: \"form\" }\n",
        "!rm -rf /content/video.mp4\n",
        "!cp -r /content/EDVR/codes/video/result/video.mp4 /content/video.mp4\n",
        "!cp -r /content/EDVR/codes/video/result/video.mp4 /content/enhanced_video.mp4\n",
        "what_next = 'download' #@param [\"play\", \"download\"]\n",
        "if what_next == \"play\":\n",
        "  display(mpy.ipython_display(\"/content/enhanced_video.mp4\", height=400, autoplay=1, loop=1, maxduration=600))\n",
        "else:\n",
        "  files.download('/content/enhanced_video.mp4')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_493e2148-21c2-4d29-8adb-32322441fda6\", \"enhanced_video.mp4\", 111561104)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWgDUMFN3_wh"
      },
      "source": [
        "#@title ##**Exit EDVR** { display-mode: \"form\" }\n",
        "#@markdown *If you are going to continue to carry out the following points, then first of all, be sure to complete this block!*\n",
        "!rm -rf /content/video.aac\n",
        "!cp -r /content/EDVR/codes/video/result/video.mp4 /content/video.mp4\n",
        "!cp -r /content/EDVR/codes/video/result/video.mp4 /content/enhanced_video.mp4\n",
        "%cd /content\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}